{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17775160.0\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.placeholder(tf.float32, shape=(D,H))\n",
    "w2 = tf.placeholder(tf.float32, shape=(H, D))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "with tf.Session() as sess :\n",
    "    values = {x: np.random.rand(N,D),\n",
    "              w1:np.random.randn(D,H),\n",
    "              w2:np.random.randn(H,D),\n",
    "              y: np.random.randn(N,D),\n",
    "             }\n",
    "    out=sess.run([loss,grad_w1,grad_w2 ],feed_dict=values)\n",
    "    loss_val,grad_w1_val,grad_w2_val = out\n",
    "    print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984.6385\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.placeholder(tf.float32, shape=(D,H))\n",
    "w2 = tf.placeholder(tf.float32, shape=(H, D))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "with tf.Session() as sess :\n",
    "    values = {x: np.random.rand(N,D),\n",
    "              w1:np.random.randn(D,H),\n",
    "              w2:np.random.randn(H,D),\n",
    "              y: np.random.randn(N,D),\n",
    "             }\n",
    "    learning_rate = 1e-5\n",
    "    for t in range(50):\n",
    "        out = sess.run([loss,grad_w1,grad_w2],\n",
    "                      feed_dict=values)\n",
    "        loss_val,grad_w1_val,grad_w2_val = out\n",
    "        values[w1] -= learning_rate * grad_w1_val\n",
    "        values[w2] -= learning_rate * grad_w2_val\n",
    "    print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n",
      "50131704.0\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D,H)))\n",
    "w2 = tf.Variable(tf.random_normal((H,D))) \n",
    "\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "\n",
    "learning_rate = 1e-5\n",
    "new_w1= w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2= w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    for t in range(50) :\n",
    "        loss_val, = sess.run([loss], feed_dict=values)\n",
    "        print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51132416.0\n",
      "16839278.0\n",
      "8529546.0\n",
      "4836349.5\n",
      "2928376.0\n",
      "1853306.8\n",
      "1211282.1\n",
      "811381.6\n",
      "553942.9\n",
      "383772.38\n",
      "269229.94\n",
      "190952.16\n",
      "136693.27\n",
      "98654.67\n",
      "71729.73\n",
      "52518.42\n",
      "38709.414\n",
      "28722.008\n",
      "21459.615\n",
      "16153.096\n",
      "12259.066\n",
      "9388.467\n",
      "7262.4683\n",
      "5686.8936\n",
      "4514.6064\n",
      "3639.7476\n",
      "2984.9019\n",
      "2493.5845\n",
      "2124.031\n",
      "1845.4594\n",
      "1635.0466\n",
      "1475.824\n",
      "1355.2313\n",
      "1263.7169\n",
      "1194.2114\n",
      "1141.4114\n",
      "1101.2821\n",
      "1070.7122\n",
      "1047.4595\n",
      "1029.8285\n",
      "1016.45605\n",
      "1006.31055\n",
      "998.6127\n",
      "992.79834\n",
      "988.41656\n",
      "985.1138\n",
      "982.62024\n",
      "980.7409\n",
      "979.3237\n",
      "978.25433\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D,H)))\n",
    "w2 = tf.Variable(tf.random_normal((H,D)))\n",
    "\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2 , axis=1))\n",
    "grad_w1,grad_w2=tf.gradients(loss,[w1,w2])\n",
    "\n",
    "learning_rate = 1e-5\n",
    "new_w1= w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2= w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "updates = tf.group(new_w1, new_w2)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "    losses = []\n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49946490.0\n",
      "17278164.0\n",
      "9020868.0\n",
      "5275096.5\n",
      "3300093.5\n",
      "2161130.5\n",
      "1464787.5\n",
      "1019903.2\n",
      "724542.6\n",
      "522960.7\n",
      "382272.88\n",
      "282401.47\n",
      "210449.89\n",
      "158123.16\n",
      "119590.97\n",
      "91006.77\n",
      "69663.46\n",
      "53601.086\n",
      "41425.906\n",
      "32163.652\n",
      "25096.148\n",
      "19683.098\n",
      "15519.533\n",
      "12305.248\n",
      "9815.6455\n",
      "7882.452\n",
      "6376.6865\n",
      "5204.8633\n",
      "4290.666\n",
      "3575.796\n",
      "3016.3608\n",
      "2577.7134\n",
      "2232.6575\n",
      "1962.0471\n",
      "1749.4087\n",
      "1582.1215\n",
      "1450.284\n",
      "1346.0233\n",
      "1264.186\n",
      "1199.8176\n",
      "1149.1849\n",
      "1109.2684\n",
      "1077.8341\n",
      "1053.109\n",
      "1033.6976\n",
      "1018.4908\n",
      "1006.6124\n",
      "997.3285\n",
      "990.07477\n",
      "984.4287\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D,H)))\n",
    "w2 = tf.Variable(tf.random_normal((H,D)))\n",
    "\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff * diff , axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "    losses = []\n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48684.883\n",
      "48640.76\n",
      "48596.723\n",
      "48552.76\n",
      "48508.8\n",
      "48464.938\n",
      "48421.223\n",
      "48377.312\n",
      "48333.715\n",
      "48290.1\n",
      "48246.54\n",
      "48202.96\n",
      "48159.645\n",
      "48116.18\n",
      "48072.85\n",
      "48029.586\n",
      "47986.332\n",
      "47943.242\n",
      "47900.188\n",
      "47857.043\n",
      "47814.027\n",
      "47771.12\n",
      "47728.31\n",
      "47685.496\n",
      "47642.76\n",
      "47599.984\n",
      "47557.35\n",
      "47514.85\n",
      "47472.273\n",
      "47429.85\n",
      "47387.41\n",
      "47345.01\n",
      "47302.77\n",
      "47260.54\n",
      "47218.254\n",
      "47176.28\n",
      "47134.145\n",
      "47092.066\n",
      "47050.164\n",
      "47008.273\n",
      "46966.34\n",
      "46924.57\n",
      "46882.883\n",
      "46841.203\n",
      "46799.47\n",
      "46757.984\n",
      "46716.418\n",
      "46675.008\n",
      "46633.6\n",
      "46592.266\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.Variable(tf.random_normal((D,H)))\n",
    "w2 = tf.Variable(tf.random_normal((H,D)))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "  \n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0954053\n",
      "3.0953727\n",
      "3.095339\n",
      "3.0953057\n",
      "3.0952725\n",
      "3.0952413\n",
      "3.0952103\n",
      "3.095178\n",
      "3.0951443\n",
      "3.095111\n",
      "3.095078\n",
      "3.0950456\n",
      "3.095014\n",
      "3.0949807\n",
      "3.0949469\n",
      "3.0949154\n",
      "3.0948815\n",
      "3.0948489\n",
      "3.0948167\n",
      "3.0947847\n",
      "3.094752\n",
      "3.09472\n",
      "3.0946867\n",
      "3.0946527\n",
      "3.0946195\n",
      "3.094585\n",
      "3.0945542\n",
      "3.094521\n",
      "3.0944874\n",
      "3.094454\n",
      "3.0944211\n",
      "3.0943878\n",
      "3.0943568\n",
      "3.0943234\n",
      "3.0942898\n",
      "3.094257\n",
      "3.0942261\n",
      "3.0941935\n",
      "3.0941608\n",
      "3.0941265\n",
      "3.0940938\n",
      "3.094062\n",
      "3.0940297\n",
      "3.093997\n",
      "3.0939639\n",
      "3.0939305\n",
      "3.093897\n",
      "3.0938663\n",
      "3.0938337\n",
      "3.0938008\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "\n",
    "init = tf.variance_scaling_initializer(2.0)\n",
    "h = tf.layers.dense(inputs=x , units=H,\n",
    "       activation = tf.nn.relu, kernel_initializer=init)\n",
    "y_pred = tf.layers.dense(inputs=h, units = D,\n",
    "        kernel_initializer=init)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "  \n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1644548\n",
      "1.1284827\n",
      "1.1001644\n",
      "1.0773501\n",
      "1.0586584\n",
      "1.0431113\n",
      "1.0300074\n",
      "1.0188591\n",
      "1.0093026\n",
      "1.0010321\n",
      "0.99384534\n",
      "0.98751396\n",
      "0.98188955\n",
      "0.97685075\n",
      "0.9723217\n",
      "0.96820366\n",
      "0.96443\n",
      "0.96095204\n",
      "0.9577241\n",
      "0.9547107\n",
      "0.95186466\n",
      "0.9491547\n",
      "0.94655204\n",
      "0.9440284\n",
      "0.9415778\n",
      "0.9391849\n",
      "0.9368395\n",
      "0.9345269\n",
      "0.9322398\n",
      "0.9299672\n",
      "0.9277007\n",
      "0.925439\n",
      "0.9231734\n",
      "0.92089885\n",
      "0.9186123\n",
      "0.9163075\n",
      "0.9139829\n",
      "0.9116364\n",
      "0.90926456\n",
      "0.906868\n",
      "0.90444076\n",
      "0.901981\n",
      "0.89949346\n",
      "0.8969695\n",
      "0.8944129\n",
      "0.89181876\n",
      "0.8891893\n",
      "0.88651997\n",
      "0.8838101\n",
      "0.88106066\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D,),\n",
    "                                activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "y_pred = model(x)\n",
    "loss= tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e0)\n",
    "updates= optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x : np.random.randn(N,D),\n",
    "              y : np.random.randn(N,D), }\n",
    "    \n",
    "  \n",
    "    for t in range(50):\n",
    "        loss_val, _ = sess.run([loss, updates] ,  feed_dict = values)\n",
    "        print(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 1.1654\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1274\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.0978\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.0740\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.0546\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.0385\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.0250\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.0136\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.0038\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.9954\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.9881\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.9817\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.9761\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.9711\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.9666\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.9626\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.9589\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.9555\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.9524\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.9494\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.9467\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.9441\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.9416\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.9392\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.9368\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.9346\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.9323\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.9302\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.9280\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.9258\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.9237\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.9215\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.9194\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.9173\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.9151\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.9129\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.9107\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.9085\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.9063\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.9040\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.9017\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.8993\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.8970\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.8946\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8921\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8897\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.8872\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 0s 249us/step - loss: 0.8846\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8821\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8794\n"
     ]
    }
   ],
   "source": [
    "N,D,H = 64,1000,100\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D,),\n",
    "                                activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mean_squared_error,\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=1e0))\n",
    "\n",
    "x= np.random.randn(N,D)\n",
    "y= np.random.randn(N,D)\n",
    "\n",
    "history = model.fit(x,y, epochs=50 , batch_size = N )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNlab",
   "language": "python",
   "name": "nnlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
